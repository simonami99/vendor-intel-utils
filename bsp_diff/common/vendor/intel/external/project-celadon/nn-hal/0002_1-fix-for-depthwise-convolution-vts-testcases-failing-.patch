From c3a0b22ef52a5f01e944e5129ec828f485a9f62e Mon Sep 17 00:00:00 2001
From: Lakshmishree C <Lakshmishree C lakshmishree.c@intel.com>
Date: Thu, 5 Sep 2019 17:13:12 +0530
Subject: [PATCH] fix for depthwise convolution vts testcases failing due to
 output mismatch

Change-Id: Ic3005244421a53930fb7f5374a505d069594a067
Signed-off-by: Lakshmishree C <Lakshmishree C lakshmishree.c@intel.com>
---
 intel_nn_hal/PreparedModel.cpp   | 9 ---------
 intel_nn_hal/graphAPI/IRLayers.h | 4 ++--
 2 files changed, 2 insertions(+), 11 deletions(-)

diff --git a/intel_nn_hal/PreparedModel.cpp b/intel_nn_hal/PreparedModel.cpp
index b484855..c06b499 100644
--- a/intel_nn_hal/PreparedModel.cpp
+++ b/intel_nn_hal/PreparedModel.cpp
@@ -1471,11 +1471,6 @@ bool PreparedModel::isOperationSupported(const Operation& operation, const Model
             // filter in == channel
             // Check Input/Filter  Operand type
 
-            if (oper_size == EXPL_PAD_PARAMS_CONV) {
-                VLOG(L1, "NNERR: Explicit padding not supported!!");
-                return false;
-            }
-
             if (input0.type != OperandType::TENSOR_FLOAT32 ||
                 input1.type != OperandType::TENSOR_FLOAT32 ||
                 input2.type != OperandType::TENSOR_FLOAT32) {
@@ -1568,10 +1563,6 @@ bool PreparedModel::isOperationSupported(const Operation& operation, const Model
 
             int oper_size = operation.inputs.size();
 
-            if (oper_size == EXPL_PAD_PARAMS_DW_CONV) {
-                VLOG(L1, "NNERR: Explicit padding not supported!!");
-                return false;
-            }
             // Check Input/Filter  Operand type
             if (input0.type != OperandType::TENSOR_FLOAT32 ||
                 input1.type != OperandType::TENSOR_FLOAT32 ||
diff --git a/intel_nn_hal/graphAPI/IRLayers.h b/intel_nn_hal/graphAPI/IRLayers.h
index 3ce7c94..10fcdae 100644
--- a/intel_nn_hal/graphAPI/IRLayers.h
+++ b/intel_nn_hal/graphAPI/IRLayers.h
@@ -70,8 +70,8 @@ inline OutputPort addOutput(const IRLayer &layer, const InferenceEngine::SizeVec
     } else if (dims.size() == 4) {
         std::cout << "addOutput dims size " << dims.size() << std::endl;
         // InferenceEngine::TensorDesc td(g_layer_precision, dims, InferenceEngine::Layout::ANY);
-        InferenceEngine::TensorDesc td(g_layer_precision, dims, InferenceEngine::Layout::NCHW);
-        // InferenceEngine::TensorDesc td(g_layer_precision, dims, InferenceEngine::Layout::NHWC);
+        // InferenceEngine::TensorDesc td(g_layer_precision, dims, InferenceEngine::Layout::NCHW);
+        InferenceEngine::TensorDesc td(g_layer_precision, dims, InferenceEngine::Layout::NHWC);
         data = std::make_shared<InferenceEngine::Data>(d_name, td);
 
     } else {
-- 
2.17.1

