From af4d0a62faea8618d739a2040548ba58708df50c Mon Sep 17 00:00:00 2001
From: hangliu1 <hang1.liu@linux.intel.com>
Date: Mon, 3 Jul 2023 08:31:56 -0400
Subject: [PATCH 6/8] drivers: virtgpu: Add support for gem buffer import

Scatter gather gem buffer created from i915 could
be imported to virtio gpu driver and make it as
a framebuffer later directly.

Tracked-On: OAM-110757
Signed-off-by: hangliu1 <hang1.liu@linux.intel.com>
Signed-off-by: ZhuChenyanX <zhucx@intel.com>
---
 drivers/gpu/drm/virtio/virtgpu_drv.h    |  6 ++
 drivers/gpu/drm/virtio/virtgpu_object.c |  4 +-
 drivers/gpu/drm/virtio/virtgpu_prime.c  | 85 ++++++++++++++++++++++++-
 3 files changed, 92 insertions(+), 3 deletions(-)

diff --git a/drivers/gpu/drm/virtio/virtgpu_drv.h b/drivers/gpu/drm/virtio/virtgpu_drv.h
index 2b50af90e11d..41c3333c9195 100644
--- a/drivers/gpu/drm/virtio/virtgpu_drv.h
+++ b/drivers/gpu/drm/virtio/virtgpu_drv.h
@@ -445,6 +445,12 @@ bool virtio_gpu_is_shmem(struct virtio_gpu_object *bo);
 int virtio_gpu_resource_id_get(struct virtio_gpu_device *vgdev,
 			       uint32_t *resid);
 
+void virtio_gpu_resource_id_put(struct virtio_gpu_device *vgdev, uint32_t id);
+
+void virtio_gpu_object_save_restore_list(struct virtio_gpu_device *vgdev,
+					 struct virtio_gpu_object *bo,
+					 struct virtio_gpu_object_params *params);
+
 int virtio_gpu_object_restore_all(struct virtio_gpu_device *vgdev);
 
 /* virtgpu_prime.c */
diff --git a/drivers/gpu/drm/virtio/virtgpu_object.c b/drivers/gpu/drm/virtio/virtgpu_object.c
index 41ca707f71f3..ef8fd5363811 100644
--- a/drivers/gpu/drm/virtio/virtgpu_object.c
+++ b/drivers/gpu/drm/virtio/virtgpu_object.c
@@ -54,14 +54,14 @@ int virtio_gpu_resource_id_get(struct virtio_gpu_device *vgdev, uint32_t *resid)
 	return 0;
 }
 
-static void virtio_gpu_resource_id_put(struct virtio_gpu_device *vgdev, uint32_t id)
+void virtio_gpu_resource_id_put(struct virtio_gpu_device *vgdev, uint32_t id)
 {
 	if (!virtio_gpu_virglrenderer_workaround) {
 		ida_free(&vgdev->resource_ida, id - 1);
 	}
 }
 
-static void virtio_gpu_object_save_restore_list(struct virtio_gpu_device *vgdev,
+void virtio_gpu_object_save_restore_list(struct virtio_gpu_device *vgdev,
 						struct virtio_gpu_object *bo,
 						struct virtio_gpu_object_params *params)
 {
diff --git a/drivers/gpu/drm/virtio/virtgpu_prime.c b/drivers/gpu/drm/virtio/virtgpu_prime.c
index e45dbf14b307..169482767b69 100644
--- a/drivers/gpu/drm/virtio/virtgpu_prime.c
+++ b/drivers/gpu/drm/virtio/virtgpu_prime.c
@@ -138,9 +138,92 @@ struct drm_gem_object *virtgpu_gem_prime_import(struct drm_device *dev,
 	return drm_gem_prime_import(dev, buf);
 }
 
+static int virtio_gpu_sgt_to_mem_entry(struct virtio_gpu_device *vgdev,
+				       struct sg_table *table,
+				       struct virtio_gpu_mem_entry **ents,
+				       unsigned int *nents)
+{
+	struct scatterlist *sg;
+	int si;
+
+	bool use_dma_api = !virtio_has_dma_quirk(vgdev->vdev);
+	if (use_dma_api)
+		*nents = table->nents;
+	else
+		*nents = table->orig_nents;
+
+	*ents = kvmalloc_array(*nents,
+			       sizeof(struct virtio_gpu_mem_entry),
+			       GFP_KERNEL);
+	if (!(*ents)) {
+		DRM_ERROR("failed to allocate ent list\n");
+		return -ENOMEM;
+	}
+
+	if (use_dma_api) {
+		for_each_sgtable_dma_sg(table, sg, si) {
+			(*ents)[si].addr = cpu_to_le64(sg_dma_address(sg));
+			(*ents)[si].length = cpu_to_le32(sg_dma_len(sg));
+			(*ents)[si].padding = 0;
+		}
+	} else {
+		for_each_sgtable_sg(table, sg, si) {
+			(*ents)[si].addr = cpu_to_le64(sg_phys(sg));
+			(*ents)[si].length = cpu_to_le32(sg->length);
+			(*ents)[si].padding = 0;
+		}
+	}
+
+	return 0;
+
+}
+
 struct drm_gem_object *virtgpu_gem_prime_import_sg_table(
 	struct drm_device *dev, struct dma_buf_attachment *attach,
 	struct sg_table *table)
 {
-	return ERR_PTR(-ENODEV);
+	size_t size = PAGE_ALIGN(attach->dmabuf->size);
+	struct virtio_gpu_device *vgdev = dev->dev_private;
+	struct virtio_gpu_object_params params = { 0 };
+	struct virtio_gpu_object *bo;
+	struct drm_gem_object *obj;
+	struct virtio_gpu_mem_entry *ents;
+	unsigned int nents;
+	int ret;
+
+	if (!vgdev->has_resource_blob || vgdev->has_virgl_3d) {
+		return ERR_PTR(-ENODEV);
+	}
+
+	obj = drm_gem_shmem_prime_import_sg_table(dev, attach, table);
+	if (IS_ERR(obj)) {
+		return ERR_CAST(obj);
+	}
+
+	bo = gem_to_virtio_gpu_obj(obj);
+	ret = virtio_gpu_resource_id_get(vgdev, &bo->hw_res_handle);
+	if (ret < 0) {
+		return ret;
+	}
+
+	ret = virtio_gpu_sgt_to_mem_entry(vgdev, table, &ents, &nents);
+	if (ret != 0) {
+		goto err_put_id;
+	}
+
+	bo->guest_blob = true;
+	params.blob_mem = VIRTGPU_BLOB_MEM_GUEST;
+	params.blob_flags = VIRTGPU_BLOB_FLAG_USE_SHAREABLE;
+	params.blob = true;
+	params.size = size;
+
+	virtio_gpu_cmd_resource_create_blob(vgdev, bo, &params,
+					    ents, nents);
+	virtio_gpu_object_save_restore_list(vgdev, bo, &params);
+
+	return obj;
+
+err_put_id:
+	virtio_gpu_resource_id_put(vgdev, bo->hw_res_handle);
+	return ret;
 }
-- 
2.17.1

